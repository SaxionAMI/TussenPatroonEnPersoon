<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="nl" xml:lang="nl"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.55">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Toekomst: Grenzen vervagen – Tussen patroon en persoon</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<link href="./40_actie.html" rel="next">
<link href="./20_uitdagingen.html" rel="prev">
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "Geen resultaten",
    "search-matching-documents-text": "Gevonden documenten",
    "search-copy-link-title": "Kopieer link om te zoeken",
    "search-hide-matches-text": "Extra overeenkomsten verbergen",
    "search-more-match-text": "meer overeenkomst in dit document",
    "search-more-matches-text": "meer overeenkomsten in dit document",
    "search-clear-button-title": "Wissen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Annuleren",
    "search-submit-button-title": "Verzenden",
    "search-label": "Zoeken"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="resources/rede.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Schakel zijbalknavigatie" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./30_toekomst.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Toekomst: Grenzen vervagen</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Schakel zijbalknavigatie" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Tussen patroon en persoon</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Voorwoord: Denken in patronen</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_introductie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introductie: Over AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_uitdagingen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Uitdagingen: Het belang van wederzijds begrip</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./30_toekomst.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Toekomst: Grenzen vervagen</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./40_actie.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Actie: Samen verantwoordelijk</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nawoord.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nawoord</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./over.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Over deze rede</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./referenties.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referenties</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Inhoudsopgave</h2>
   
  <ul>
  <li><a href="#oneindige-technologische-groei" id="toc-oneindige-technologische-groei" class="nav-link active" data-scroll-target="#oneindige-technologische-groei"><span class="header-section-number">3.1</span> Oneindige technologische groei?</a></li>
  <li><a href="#de-horizon-van-ai" id="toc-de-horizon-van-ai" class="nav-link" data-scroll-target="#de-horizon-van-ai"><span class="header-section-number">3.2</span> De horizon van AI</a></li>
  <li><a href="#de-horizon-van-mensen" id="toc-de-horizon-van-mensen" class="nav-link" data-scroll-target="#de-horizon-van-mensen"><span class="header-section-number">3.3</span> De horizon van mensen</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-toekomst" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Toekomst: Grenzen vervagen</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><strong>Samenvatting</strong></p>
<p>Hoe ver gaan we met AI? Met wat fantasie kunnen we allerlei innovaties bedenken en zelfs verwachten dat AI slimmer wordt dan mensen. Voordat we zover komen, zijn er nog vele onderwerpen die onderzocht moeten worden. Het meest belangrijke is dat we onszelf de vraag stellen wat we willen bereiken met AI, en wat ons mens maakt. AI kunnen we zien als een goede samenwerkingspartner als we hier zelf slim mee omgaan.</p>
</blockquote>
<p>Maar hoe dan verder? Wat valt er te verwachten van AI de komende jaren en zelfs decennia? Komen we in een winter terecht, of beginnen hierna de zomerdagen van AI? Koffiedik kijken kent risico’s, en ik zal me niet wagen aan concrete voorspellingen voor de jaren hierna. Wel belicht ik hieronder verwachtingen die anderen hebben, en durf ik het aan om te speculeren over de relatie tussen mens en machine.</p>
<section id="oneindige-technologische-groei" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="oneindige-technologische-groei"><span class="header-section-number">3.1</span> Oneindige technologische groei?</h2>
<p>Ik benoemde eerder al dat mensen onlosmakelijk verbonden zijn met technologie. Vanaf het moment dat we bepaalde gereedschappen (<em>tools</em>) zijn gebruiken, hebben we ons verder kunnen ontwikkelen en heeft onze evolutie sindsdien veel meer mentaal dan fysiek plaatsgevonden <span class="citation" data-cites="Dennett2017">(<a href="referenties.html#ref-Dennett2017" role="doc-biblioref">Dennett, 2017</a>)</span>. Van een paar miljoen jaar geleden tot nu zijn er veel uitvindingen gedaan, van stenen bijlen tot quantumcomputers. Als we deze historie bekijken zien we echter ook een patroon. Technologie versnelt. Dat wil zeggen: uitvindingen van nieuwe gereedschappen en vorderingen in technologie lijken elkaar steeds sneller op te volgen. Er zit bijvoorbeeld minder tijd tussen het kunnen gebruiken van elektriciteit (1825, de electromagneet) en de eerste digitale computer (1941, de Z3 <span class="citation" data-cites="rojas1997konrad">(<a href="referenties.html#ref-rojas1997konrad" role="doc-biblioref">Rojas, 1997</a>)</span>), dan tussen de start van de Bronzen en IJzeren Tijdperken (3.300 en 1.200 voor Christus). De technologische groei zien we bijvoorbeeld ook in de industriële revoluties: rond het jaar 1800 maakte de industrie automatisering door. Allerlei processen in de maakindustrie konden plotseling veel sneller plaatsvinden. Daarna kwamen een revolutie rond het jaar 1900 dankzij communicatienetwerken en het gebruik van elektriciteit. De derde revolutie in deze lijn kwam dankzij digitale computers in de tweede helft van de 20e eeuw. En nu, in de vierde industriële revolutie, draait het om de verbinding van de analoge met de digitale wereld dankzij vakgebieden als het <strong>Internet of Things</strong> (IoT) en AI <span class="citation" data-cites="lasi2014industry">(<a href="referenties.html#ref-lasi2014industry" role="doc-biblioref">Lasi e.a., 2014</a>)</span>.</p>
<p>Kijkend naar de afgelopen vijftig jaar zien we ook dat het gebruik van computers duidelijk is toegenomen. Over de hele wereld gebruikte in 2023 ongeveer 69% van de bevolking smartphones.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Als we denken aan de bevolkingsgroei van onze planeet, zien we ook dat dat sneller en sneller gaat. Voor computerchips geldt eenzelfde soort groei volgens de <strong>Wet van Moore</strong>: het aantal transistoren op chips verdubbelt iedere twee jaar <span class="citation" data-cites="enwiki:1250511271">(<a href="referenties.html#ref-enwiki:1250511271" role="doc-biblioref">Wikipedia contributors, 2024a</a>)</span>. Dit is gegroeid van 2.300 transistoren in de Intel 4004 (1971) naar 7,5 miljoen transistoren in de Pentium II (1997) tot meer dan 100 miljard transistoren in de Ryzen EPYC (2024).</p>
<p>Dit soort groei wordt exponentieel genoemd: hoe groter iets wordt, hoe sneller het groeit. Dit is een lastig te overzien patroon. Mensen kunnen lineaire groei prima begrijpen, maar exponentiële groei is lastiger om te bevatten. Als het gras in een tuin iedere week vijf centimeter groeit, snappen we snel wanneer we moeten maaien om er nog overheen en niet doorheen te lopen. Als het gras exponentieel zou groeien, en iedere week zou verdubbelen in lengte, dan zou gras van 5 cm na een maand 80 cm lang zijn en na een jaar iets meer dan 225 miljard kilometer.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Andersom gedacht, als een vijver na een maand voor 10% is dichtgegroeid met planten, en deze planten verdubbelen iedere dag, hoe lang duurt het dan nog voor de vijver overvol zit? Slechts vier dagen.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Hoeveel tijd er daarvoor is gespendeerd aan die verdubbeling in groei is niet belangrijk en daardoor kan iets wat schijnbaar klein is onverwacht snel groot worden.</p>
<p>Deze versnellende snelheid van technologie wordt door sommigen gezien als iets dat gaat leiden tot een <strong>technologische singulariteit</strong>. Als onze computers steeds sneller worden en technologieën zoals AI zich ook sneller ontwikkelen, wat gebeurt er dan op een gegeven moment? Een explosie van intelligentie, dankzij machines die zelf leren en zichzelf verbeteren. Intelligentie is een ruim begrip, en zien we dat computers op bepaalde vlakken al intelligenter zijn dan mensen. Allicht gaat de discussie dan ook meer over <strong>Artificial General Intelligence</strong> (AGI): generieke artificiële intelligentie. AGI betekent dat deze kunstmatige intelligentie niet louter één taak beter kan dan mensen, maar verschillende taken, en op een hoger niveau van begrip, waardoor deze kan leren van diens eigen ervaringen.</p>
<p>De explosie van intelligentie is een hypothese van verschillende wetenschappers <span class="citation" data-cites="good1966speculations vinge1993technological chalmers2016singularity">(<a href="referenties.html#ref-chalmers2016singularity" role="doc-biblioref">Chalmers, 2016</a>; <a href="referenties.html#ref-good1966speculations" role="doc-biblioref">Good, 1966</a>; <a href="referenties.html#ref-vinge1993technological" role="doc-biblioref">Vinge, 1993</a>)</span>. Deze singulariteit is een punt in de tijd waarna ontwikkelingen niet meer voor te stellen zijn, omdat deze gedreven zullen zijn door bovenmenselijke intelligentie.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Een ander, vaak aangehaald werk hierover, komt van Ray Kurzweil, die inschatte dat deze gebeurtenis in 2045 zal plaatsvinden <span class="citation" data-cites="kurzweil2005singularity">(<a href="referenties.html#ref-kurzweil2005singularity" role="doc-biblioref">Kurzweil, 2005</a>)</span>. Al deze verwachtingen zijn gebaseerd op een interpretatie van exponentiële groei, en met name dat deze niet stopt. Hoe en of zulke super-intelligentie gaat ontstaan wordt onderbouwd met argumenten die uitgaan van betere hardware en software. In andere woorden: snellere computers of efficiëntere algoritmes. Kritiek op de singulariteit hierop is legio, zelfs van Moore, wiens wet vaak wordt aangehaald <span class="citation" data-cites="spectrum2008techluminaries">(<a href="referenties.html#ref-spectrum2008techluminaries" role="doc-biblioref">IEEE Spectrum, 2008</a>)</span>. Vraagtekens worden geplaatst bij het patroon van exponentiële groei, want het is niet zeker of deze zo doorgaat of afvlakt.</p>
<p>Mijn mening over de singulariteit is dat we niet van tevoren dienen uit te sluiten dat het mogelijk is. Dat is net zo kwalijk als met volkomen zekerheid zeggen dat het wel gebeurt. Wat volgens mij belangrijker is, is onze houding ten opzichte van dit idee en hoe we omgaan met ontwikkelingen van AI. Los van de praktische tegenargumenten op basis van technologie waar we nu beeld van hebben, kunnen we ook theoretisch kijken naar de mogelijkheden en uitdagingen van het ontstaan van <strong>super-intelligentie</strong> <span class="citation" data-cites="Bostrom2014superintelligence">(<a href="referenties.html#ref-Bostrom2014superintelligence" role="doc-biblioref">Bostrom, 2015</a>)</span>. Wat iedere intelligente ‘levensvorm’ aanjaagt zijn doelen als zelfbehoud en het nastreven van een bepaald ‘nut’. Dat laatste is wederom een groot onderwerp, maar voor veel levensvormen draait het om het behouden van de soort en dus reproductie. Wat een hypothetische AI als nut inziet, is wellicht wat die AI al dan niet bewust initieel wordt meegegeven. Een infameus gedachte-experiment hierover verhandelt over een <em>paperclip maximizer</em> wiens doel het is om zoveel mogelijk paperclips te maken <span class="citation" data-cites="bostrom2020ethical">(<a href="referenties.html#ref-bostrom2020ethical" role="doc-biblioref">Bostrom, 2020</a>)</span>. Met een beetje AI in dat systeem besluit het dat mensen wel eens dit doel in gevaar kunnen brengen en dat mensen gemaakt zijn van atomen waarmee paperclips gemaakt kunnen worden. De gevaarlijke conclusie van dat verhaal is duidelijk en niet bedoeld om schrik aan te jagen, maar om bewustzijn te creëren over ethische risico’s van het inzetten van technologie waarvan de gevolgen niet bekend zijn.</p>
<p>Voordat we zo ver vooruitblikken, lijkt het mij verstandig om eerst te kijken welke onderzoeksinnovaties nu gaande zijn. Het is goed om verder vooruit te kijken, maar ook om de blik op de grond voor ons te hebben.</p>
</section>
<section id="de-horizon-van-ai" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="de-horizon-van-ai"><span class="header-section-number">3.2</span> De horizon van AI</h2>
<p>In de vorige sectie haalde ik speculaties aan over de richting waarin AI uiteindelijk zou kunnen groeien. Voordat we die horizon bereiken, is het goed om naar de kortere termijn te kijken. AI als vakgebied staat duidelijk niet stil. De generatieve AI die de afgelopen jaren aandacht krijgt kwam niet uit de lucht vallen; hieraan werd al jaren gewerkt. De taalmodellen van onder andere ChatGPT zijn gebaseerd op werk uit 2017 over de specifieke deeplearning-architectuur <strong>transformers</strong> <span class="citation" data-cites="vaswani2017attention">(<a href="referenties.html#ref-vaswani2017attention" role="doc-biblioref">Vaswani e.a., 2017</a>)</span>. De plaatjesgeneratoren komen voort uit onderzoek naar <strong>generative adversarial networks</strong> uit 2014. Hierin worden twee AI-modellen tegenover elkaar gezet, de een om nieuwe plaatjes te genereren op basis van een dataset, de ander om te beoordelen of deze plaatjes behoren tot de originele dataset. Gaandeweg worden beide modellen steeds beter in hun taak, met als resultaat een goede plaatjesgenerator <span class="citation" data-cites="goodfellow2014generative reed2016generative">(<a href="referenties.html#ref-goodfellow2014generative" role="doc-biblioref">Goodfellow e.a., 2014</a>; <a href="referenties.html#ref-reed2016generative" role="doc-biblioref">Reed e.a., 2016</a>)</span>.</p>
<p>De vraag is natuurlijk of we nu ook kunnen bepalen welke van zulke innovaties de komende vijf á tien jaar een evengrote rol gaan spelen. Het veld van AI is breed, dus ik zal zeker niet alles kunnen benoemen. Wat ik belangrijk vind, zijn zaken die raken aan een veranderend perspectief op AI. Ten eerste twee nieuwe manieren om naar data kijken.</p>
<p>Data is een voedingsbron voor AI, en AI-modellen hebben als doel die data om te zetten in informatie. Het <em>garbage-in-garbage-out-</em>principe vat het belang van goede data samen. <strong>Data-centric AI</strong> is een eerste nieuwe blik op de zaken: hierin wordt gekeken naar AI-technieken om data te verbeteren voordat de data gebruikt wordt een AI-model te trainen <span class="citation" data-cites="zha2023data">(<a href="referenties.html#ref-zha2023data" role="doc-biblioref">Zha e.a., 2023</a>)</span>. Het idee om data te bekijken en aan te passen voordat het aan een AI-algoritme gegeven wordt is niet nieuw. Maar het inzetten van AI om die data te verbeteren biedt wel degelijk vele mogelijkheden. Een groot probleem is namelijk dat veel data slecht of niet ‘gelabeld’ is: het is niet duidelijk wat de data betekent, bijvoorbeeld wat voor iets er op een plaatje staat, of of een bepaalde waarde in een grafiek slecht of goed is. Hiervoor zijn technieken in opkomst om toch met weinig of laagkwalitatieve data goede resultaten te behalen, zoals <strong>semi-supervised learning</strong> <span class="citation" data-cites="van2020survey">(<a href="referenties.html#ref-van2020survey" role="doc-biblioref">Van Engelen &amp; Hoos, 2020</a>)</span>.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>Een tweede nieuwe blik op data gaat over de verhouding van data tot informatie, kennis en wijsheid. Dit is minder technisch ingestoken en gaat over het doel dat je met data wilt bereiken. Dit valt uit te beelden in een pyramide vorm, waarop iedere volgende laag bouwt op die daaronder <span class="citation" data-cites="fricke2019knowledge">(<a href="referenties.html#ref-fricke2019knowledge" role="doc-biblioref">Frické, 2019</a>)</span>. Deze opbouw van niveaus is simplistisch, maar het laat ons wel op een andere manier kijken naar hoe we AI kunnen gebruiken.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dikw.png" class="img-fluid figure-img"></p>
<figcaption>DIKW-pyramide</figcaption>
</figure>
</div>
<p>Een nauwe blik op AI en data-analyse is namelijk dat we data omzetten in informatie. Deze informatie laat zien wat er aan de hand is, bijvoorbeeld dat er een kat op een foto gedetecteerd wordt, of een machine een bepaalde grenswaarde gaat overstijgen en daarmee kapot zou kunnen gaan. Een niveau hoger zit echter kennis: een kat is gedetecteerd op een foto, waarom is dat zo? Wijsheid is vervolgens het inzicht waarmee een vervolgactie gepland kan worden: de machine moet stopgezet en onderhouden worden. Deze <strong>DIKW</strong>-pyramide laat zien dat we op basis van data verschillende soorten interpretaties kunnen doen. Dit helpt ons om beter te duiden waarvoor we een AI-systeem wel of niet kunnen gebruiken. Geeft zo’n systeem geen uitleg over een uitkomst? Dan is het niet goed genoeg om bepaalde beslissingen op te baseren. Zegt het niets over het effect van een bepaalde vervolgactie? Dan is het waarschijnlijk niet goed genoeg om een aanbeveling over te nemen.</p>
<p>Als we het dan over kennis hebben, is het ook belangrijk om kennis van mensen te gebruiken. Maar hoe digitaliseren we die kennis? Het vakgebied van <strong>knowledge representation</strong> (kennisrepresentatie) gaat hierover: hoe slaan we kennis op en kunnen we deze vervolgens gebruiken met computers? Hier komt de klassieke, symbolische AI weer om de hoek kijken in de vorm van <strong>knowledge graphs</strong> <span class="citation" data-cites="ji2021survey">(<a href="referenties.html#ref-ji2021survey" role="doc-biblioref">Ji e.a., 2021</a>)</span>. In plaats van datagedreven allerlei data te verzamelen, gaat dit over verbanden tussen concepten. Bijvoorbeeld dat deze zin bestaat uit woorden en leestekens, en dat die woorden bestaan uit letters. Dit kan worden uitgedrukt in een graaf die die verbanden laat zien, en waarin vervolgens een algoritme patronen kan opsporen en relaties kan doorgronden. Om kennis op een eenvoudige manier uit mensen te krijgen, kunnen bijvoorbeeld taalmodellen ingezet worden om deze verbanden vast te leggen, op basis van interviews en geschreven documenten <span class="citation" data-cites="pan2024unifying">(<a href="referenties.html#ref-pan2024unifying" role="doc-biblioref">Pan e.a., 2024</a>)</span>. Dit is een mooie samensmelting van de symbolische AI (uit de jaren ’70) en de nieuwe aanpak van grote taalmodellen op basis van <em>transformers</em> (uit de jaren ’10). Daarin zie ik grote kansen om ook weer beter verklaarbaar gedrag uit AI-systemen te krijgen, omdat inzichten uit zulke methodes weer op een uitlegbare manier naar mensen vertaald kunnen worden.</p>
<p>Ik vermoed ook dat er meer aandacht gaat gekomen voor meer verantwoord gebruik en ontwikkeling van AI.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> Wetgeving en regulering zijn gaande om beter in handen te houden wat met wiens data gebeurt, zoals in de Data Act en AI Act van de EU. <strong>Responsible AI</strong> begint al meer en meer een begrepen concept te worden <span class="citation" data-cites="dignum2019responsible">(<a href="referenties.html#ref-dignum2019responsible" role="doc-biblioref">Dignum, 2019</a>)</span>. Ook voor <strong>generative AI</strong> zoals taalmodellen en de plaatjesgeneratoren wordt onderzocht wat wel en niet wenselijk is <span class="citation" data-cites="gu2024responsible">(<a href="referenties.html#ref-gu2024responsible" role="doc-biblioref">Gu, 2024</a>)</span>.</p>
<p>Daarnaast is er ook wat te zeggen voor duurzamere AI <span class="citation" data-cites="van2021sustainable">(<a href="referenties.html#ref-van2021sustainable" role="doc-biblioref">Van Wynsberghe, 2021</a>)</span>. Wat ik eerder aanhaalde is dat grotere AI-modellen meer rekenkracht en dus meer energie nodig hebben. De rekenkracht wordt ieder jaar efficiënter, maar de vraag naar die rekenkracht stijgt ook, en harder, dus er is almaar meer energie nodig <span class="citation" data-cites="wu2022sustainable">(<a href="referenties.html#ref-wu2022sustainable" role="doc-biblioref">Wu e.a., 2022</a>)</span>. Het trainen van die modellen is maar één aspect van de levenscyclus van data voor AI. Andere fases zijn de verzameling tot experimentatie, het trainen van modellen, optimalisatie daarvan, en uiteindelijk het gebruik van een model. In ieder van die fases is winst te behalen, bijvoorbeeld via betere algoritmes. Maar een andere aanpak van de infrastructuur kan ook verbetering brengen. Op dit moment zijn veel AI-gebaseerde diensten namelijk afhankelijk van cloud-omgevingen om in te draaien. Daarvoor moet data over en weer gestuurd worden via het internet. Met efficiëntere algoritmes en AI-modellen kan AI echter ook lokaal toegepast worden <span class="citation" data-cites="deng2020edge">(<a href="referenties.html#ref-deng2020edge" role="doc-biblioref">Deng e.a., 2020</a>)</span>. Dit concept wordt <strong>edge intelligence</strong> genoemd, waarbij de intelligentie dus niet elders, in de cloud, zit, maar op een eigen systeem. Dit kent voordelen zoals onafhankelijkheid van internetverbinding en veiligheid vanwege geen communicatie met andere systemen. Vanuit duurzaamheidsoogpunt vergt dit echter ook weer een investering in kleinere, en meer computers.</p>
<p>Wat de komende tijd op de voorgrond gaat staan is de bredere inzet van de modellen die aan de huidige generatieve AI ten grondslag liggen: <strong>foundation models</strong> <span class="citation" data-cites="zhou2023comprehensive">(<a href="referenties.html#ref-zhou2023comprehensive" role="doc-biblioref">Zhou e.a., 2023</a>)</span>. Dit zijn modellen die getraind zijn met niet één doel voor ogen: ze kunnen generiek worden ingezet en zijn daarmee een stap naar <strong>Artificial General Intelligence</strong> (AGI). Dat wil zeggen dat er verschillende taken aan een model gegeven kunnen worden, zoals bij een taalmodel het schrijven van een tekst, het samenvatten daarvan of het geven van een antwoord op een vraag. Deze modellen hebben echter nog limitaties, maar die zijn op dit moment steeds minder van toepassing zijn door nieuwe ontwikkelingen. Huidige voortgang wordt bijvoorbeeld geboekt voor multimodale foundation modellen die getraind worden op zowel tekst als beeld en audio <span class="citation" data-cites="li2024multimodal">(<a href="referenties.html#ref-li2024multimodal" role="doc-biblioref">Li e.a., 2024</a>)</span>. Hoe snel deze modellen compleet generiek worden is een open vraag, ook omdat de definitie van AGI nu niet toereikend is om hier iets definitiefs over te zeggen.</p>
<p>De vraag is dan ook hoe slim AI echt is. Bij AI wordt al gauw gedacht dat zulke systemen zelf leren. Dat is echter nog niet zo. Er gaat veel werk zitten in het ophalen van de juiste data, deze verwerken, annoteren, mee experimenteren, dan het analyseren, het trainen van modellen met algoritmes, het evalueren, en uiteindelijk het inzetten. Met veel van deze stappen gaat mensenwerk gepaard. Hoe leren werkt is een vraag waarop het vakgebied <strong>meta-learning</strong> zich stort: het automatisch laten ontdekken wat een goede aanpak is om een model te trainen <span class="citation" data-cites="hospedales2021meta">(<a href="referenties.html#ref-hospedales2021meta" role="doc-biblioref">Hospedales e.a., 2021</a>)</span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Waar echter voor de komende tijd de intelligentie in zit, is volgens mij toch echt de samenwerking tussen mensen en machines.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> Hoe begrijpen we elkaar beter en kunnen wij als mensen AI optimaal en verantwoord inzetten? Dit wordt het elders <strong>hybride intelligentie</strong> genoemd <span class="citation" data-cites="akata2020research">(<a href="referenties.html#ref-akata2020research" role="doc-biblioref">Akata e.a., 2020</a>)</span>, waar ik kies voor symbiotische intelligentie. Dit licht ik toe in de volgende sectie over de volgende stappen voor mensen op weg naar onze horizon.</p>
</section>
<section id="de-horizon-van-mensen" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="de-horizon-van-mensen"><span class="header-section-number">3.3</span> De horizon van mensen</h2>
<p>Wat maakt ons mens?</p>
<p>Een vraag die ik heb uitgesteld om te beantwoorden is deze, en in het bijzonder zaken over emoties en bewustzijn. Sluitende antwoorden ga ik niet geven, en wellicht zijn die er ook niet.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> Ik haalde eerder de <strong>Turing-test</strong> aan, één van de eerste gedachte-experimenten om te bepalen of je praat met een mens of een computer. Dit gaat over het verschil tussen menselijke en kunstmatige intelligentie, wat een nauwere vraag is dan wat ‘mens zijn’ betekent. Kan een computer net zo menselijk zijn als mensen? De Turing-test zelf gaat alleen over taal, en slechts geschreven taal in de originele vorm van het experiment <span class="citation" data-cites="Turing1950ai">(<a href="referenties.html#ref-Turing1950ai" role="doc-biblioref">Turing, 1950</a>)</span>. Met de huidige <strong>large language models</strong> (LLM’s) lijkt het erop dat de Turing-test in sommige gevallen verslagen kan worden, waarbij een computer niet altijd onderscheiden kan worden van een mens <span class="citation" data-cites="elkins2020can jones2024people">(<a href="referenties.html#ref-elkins2020can" role="doc-biblioref">Elkins &amp; Chun, 2020</a>; <a href="referenties.html#ref-jones2024people" role="doc-biblioref">Jones &amp; Bergen, 2024</a>)</span>. Huidige <strong>text-to-speech</strong>-software heeft inmiddels zulke realistische uitspraak dat deze niet meer van menselijke spraak te onderscheiden is <span class="citation" data-cites="tan2024naturalspeech">(<a href="referenties.html#ref-tan2024naturalspeech" role="doc-biblioref">Tan e.a., 2024</a>)</span>. Gekoppeld aan LLM’s zou dit er ook voor kunnen zorgen dat de Turing-test ook in gesproken vorm door een computer verslagen zou kunnen worden. Een ander inzicht is dat de Turing-test mensen vooral een spiegel voorhoudt. Wat je bespreekt met een computer hangt vooral af van wie je zelf bent, dus het zal iets zeggen over je eigen blik op menselijkheid <span class="citation" data-cites="sejnowski2023large">(<a href="referenties.html#ref-sejnowski2023large" role="doc-biblioref">Sejnowski, 2023</a>)</span>.</p>
<p>Dus een vorm van AI kan menselijk gedrag vertonen. De manier waarop dit gebeurt komt steeds dichter bij wat we ervaren als mensen: in tekst, spraak, en wellicht al snel ook in beeld.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> Wat mij betreft is de interessantere vraag echter: waarom? Waarom willen we AI? Hierop zijn vele antwoorden te geven, die te maken hebben met de brede doelstellingen van het vakgebied. Ten eerste om systemen te maken die beter werken dan wat er nu is, efficiënter zijn, en nieuwe taken kunnen uitvoeren. Ten tweede om menselijke intelligentie beter te begrijpen. Ten derde: omdat het kan. Dit laatste is vaak een drijfveer van technologie. Het kan, dus we proberen het. Maar waarom willen we AI die menselijk is? Moet een AI-gebaseerd system per se menselijke intelligentie hebben om diens werk goed te doen? Moeten emoties onderdeel zijn van dit systeem?<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> Kan of moet een AI-systeem een slechte dag hebben, net als mensen dat zo hebben? Moeten AI-systemen ook menselijke normen en waarden hebben? Dit zijn gesloten vragen, maar het enige antwoord is ‘het ligt eraan.’ Context is uiterst belangrijk, dus hoe een AI-systeem wordt ingezet bepaalt wat nodig is.</p>
<p>Ik verwacht dat we anders naar intelligentie gaan kijken. Hopelijk met meer begrip van wat intelligentie inhoudt, maar ook welke normen en waarden we daaraan hangen. Respect voor elkaars (menselijke) intelligentie, maar voor andersoortige intelligenties. Op den duur verschuift, verwacht ik, het algehele beeld van wat mensen mensen maakt. We zijn verbonden met technologie, soms omdat het nodig is, vaak omdat we het gewend zijn. Mijn verwachting is dan ook dat wij steeds minder onderscheid gaan maken tussen mens en machine. Onze technologie maakt wie wij zijn, en andersom. Deze symbiose zou een <strong>co-evolutie</strong> genoemd kunnen worden <span class="citation" data-cites="lee2020coevolution">(<a href="referenties.html#ref-lee2020coevolution" role="doc-biblioref">Lee, 2020</a>)</span>. Mens en machine groeien naar elkaar toe, iets wat het <strong>transhumanisme</strong> aanhangt: het verbeteren van de mens dankzij technologie <span class="citation" data-cites="huxley2015transhumanism">(<a href="referenties.html#ref-huxley2015transhumanism" role="doc-biblioref">Huxley, 2015</a>)</span>. Wij veranderen ons leven met behulp van AI, en wij veranderen AI ook door nieuwe ontwikkelingen. Hoe we ons verhouden tot AI is een kernvraag <span class="citation" data-cites="siemens2022human">(<a href="referenties.html#ref-siemens2022human" role="doc-biblioref">Siemens e.a., 2022</a>)</span>. Of intelligentie menselijk is of niet kan op den duur minder belangrijk worden. Misschien wegen de meningen van AI op een dag net zo zwaar als die van mensen. Daarvoor zijn dan wel goede kaders nodig om te bespreken wat standpunten zijn van menselijke en kunstmatige intelligentie. Onderbouwing van argumenten is vanuit een rationeel standpunt noodzakelijk. Fundamentele discussies over het toekennen van bepaalde eigenschappen aan AI, zoals bewustzijn <span class="citation" data-cites="mcdermott2007artificial">(<a href="referenties.html#ref-mcdermott2007artificial" role="doc-biblioref">McDermott, 2007</a>)</span>, zullen blijven doorgaan. Dit zijn uiteindelijk geen technische problemen, maar menselijke uitdagingen waarover we het gesprek moeten blijven voeren.</p>
<p>Gaat AI ons leven verbeteren? Dat ligt aan onszelf. Onderliggend aan technologie en de ontwikkeling daarvan liggen normen en waarden. Deze duiden wat we belangrijk vinden en zijn ook subjectief. Het publieke debat hierover zou ruimte moeten laten voor ieders mening, en vooral ook constructief moeten zijn <span class="citation" data-cites="fast2017long brauner2023does">(<a href="referenties.html#ref-brauner2023does" role="doc-biblioref">Brauner e.a., 2023</a>; <a href="referenties.html#ref-fast2017long" role="doc-biblioref">Fast &amp; Horvitz, 2017</a>)</span>. Er is noodzaak voor transparantie over wat AI wel en niet kan, en wat daarmee gepaard gaat. Om deze boodschap nogmaals te herhalen: er is hogere AI-geletterdheid nodig. Geïnformeerde discussie hierover helpt. Zowel voor de AI-wetenschapper die niet alle meningen en gevoelens van mensen hierover kan weten, als voor de mensen die niet weten wat er allemaal met AI gepaard gaat.</p>
<p>Als we verder in de toekomst proberen te kijken, is er veel mogelijk en vooral onzeker. Als de (rode) lijn tussen mens en machine vervaagt, volgt wellicht een ultieme symbiose. Dit mogelijke punt ligt in de toekomst, misschien ver weg en misschien dichter bij dan we denken. Daarom is het belangrijk dat we verstandiger en verantwoorder omgaan met AI. We sturen zelf hoe en of we daar willen komen. Het beste moment om te beginnen met deze discussie was 70 jaar geleden; het op één na beste moment is nu. In het volgende hoofdstuk belicht ik hoe we dat kunnen gaan doen.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list" style="display: none">
<div id="ref-akata2020research" class="csl-entry" role="listitem">
Akata, Z., Balliet, D., De Rijke, M., Dignum, F., Dignum, V., Eiben, G., Fokkens, A., Grossi, D., Hindriks, K., Hoos, H., e.a. (2020). A research agenda for hybrid intelligence: augmenting human intellect with collaborative, adaptive, responsible, and explainable artificial intelligence. <em>Computer</em>, <em>53</em>(8), 18–28.
</div>
<div id="ref-Bostrom2014superintelligence" class="csl-entry" role="listitem">
Bostrom, N. (2015). <em>Superintelligence: Paths, Dangers, Strategies</em>. Oxford University Press.
</div>
<div id="ref-bostrom2020ethical" class="csl-entry" role="listitem">
Bostrom, N. (2020). Ethical issues in advanced artificial intelligence. <em>Machine Ethics and Robot Ethics</em>, 69–75.
</div>
<div id="ref-brandtzaeg2022my" class="csl-entry" role="listitem">
Brandtzaeg, P. B., Skjuve, M., &amp; Følstad, A. (2022). My AI friend: How users of a social chatbot understand their human–AI friendship. <em>Human Communication Research</em>, <em>48</em>(3), 404–429.
</div>
<div id="ref-brauner2023does" class="csl-entry" role="listitem">
Brauner, P., Hick, A., Philipsen, R., &amp; Ziefle, M. (2023). What does the public think about artificial intelligence?—A criticality map to understand bias in the public perception of AI. <em>Frontiers in Computer Science</em>, <em>5</em>, 1113903.
</div>
<div id="ref-chalmers2016singularity" class="csl-entry" role="listitem">
Chalmers, D. J. (2016). The singularity: A philosophical analysis. <em>Science fiction and philosophy: From time travel to superintelligence</em>, 171–224.
</div>
<div id="ref-deng2020edge" class="csl-entry" role="listitem">
Deng, S., Zhao, H., Fang, W., Yin, J., Dustdar, S., &amp; Zomaya, A. Y. (2020). Edge intelligence: The confluence of edge computing and artificial intelligence. <em>IEEE Internet of Things Journal</em>, <em>7</em>(8), 7457–7469.
</div>
<div id="ref-Dennett2017" class="csl-entry" role="listitem">
Dennett, D. (2017). <em>From Bacteria to Bach and Back: The Evolution of Minds</em>. W. W. Norton &amp; Company.
</div>
<div id="ref-dignum2019responsible" class="csl-entry" role="listitem">
Dignum, V. (2019). <em>Responsible artificial intelligence: how to develop and use AI in a responsible way</em> (Vol. 2156). Springer.
</div>
<div id="ref-elkins2020can" class="csl-entry" role="listitem">
Elkins, K., &amp; Chun, J. (2020). Can GPT-3 pass a writer’s Turing test? <em>Journal of Cultural Analytics</em>, <em>5</em>(2).
</div>
<div id="ref-fast2017long" class="csl-entry" role="listitem">
Fast, E., &amp; Horvitz, E. (2017). Long-term trends in the public perception of artificial intelligence. <em>Proceedings of the AAAI conference on artificial intelligence</em>, <em>31</em>.
</div>
<div id="ref-fricke2019knowledge" class="csl-entry" role="listitem">
Frické, M. (2019). The knowledge pyramid: the DIKW hierarchy. <em>Ko Knowledge organization</em>, <em>46</em>(1), 33–46.
</div>
<div id="ref-good1966speculations" class="csl-entry" role="listitem">
Good, I. J. (1966). Speculations concerning the first ultraintelligent machine. In <em>Advances in computers</em> (Vol. 6, pp. 31–88). Elsevier.
</div>
<div id="ref-goodfellow2014generative" class="csl-entry" role="listitem">
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., &amp; Bengio, Y. (2014). Generative adversarial nets. <em>Advances in neural information processing systems</em>, <em>27</em>.
</div>
<div id="ref-gu2024responsible" class="csl-entry" role="listitem">
Gu, J. (2024). Responsible generative ai: What to generate and what not. <em>arXiv preprint arXiv:2404.05783</em>.
</div>
<div id="ref-hospedales2021meta" class="csl-entry" role="listitem">
Hospedales, T., Antoniou, A., Micaelli, P., &amp; Storkey, A. (2021). Meta-learning in neural networks: A survey. <em>IEEE transactions on pattern analysis and machine intelligence</em>, <em>44</em>(9), 5149–5169.
</div>
<div id="ref-huxley2015transhumanism" class="csl-entry" role="listitem">
Huxley, J. (2015). Transhumanism. <em>Ethics in Progress</em>, <em>6</em>(1), 12–16.
</div>
<div id="ref-spectrum2008techluminaries" class="csl-entry" role="listitem">
IEEE Spectrum. (2008). <em>Tech Luminaries Address Singularity</em>. <a href="https://spectrum-ieee-org.saxion.idm.oclc.org/tech-luminaries-address-singularity" class="uri">https://spectrum-ieee-org.saxion.idm.oclc.org/tech-luminaries-address-singularity</a>.
</div>
<div id="ref-ji2021survey" class="csl-entry" role="listitem">
Ji, S., Pan, S., Cambria, E., Marttinen, P., &amp; Philip, S. Y. (2021). A survey on knowledge graphs: Representation, acquisition, and applications. <em>IEEE transactions on neural networks and learning systems</em>, <em>33</em>(2), 494–514.
</div>
<div id="ref-jones2024people" class="csl-entry" role="listitem">
Jones, C. R., &amp; Bergen, B. K. (2024). People cannot distinguish GPT-4 from a human in a Turing test. <em>arXiv preprint arXiv:2405.08007</em>.
</div>
<div id="ref-kurzweil2005singularity" class="csl-entry" role="listitem">
Kurzweil, R. (2005). The singularity is near. In <em>Ethics and emerging technologies</em> (pp. 393–406). Springer.
</div>
<div id="ref-lasi2014industry" class="csl-entry" role="listitem">
Lasi, H., Fettke, P., Kemper, H.-G., Feld, T., &amp; Hoffmann, M. (2014). Industry 4.0. <em>Business &amp; information systems engineering</em>, <em>6</em>, 239–242.
</div>
<div id="ref-lee2020coevolution" class="csl-entry" role="listitem">
Lee, E. A. (2020). <em>The coevolution: The entwined futures of humans and machines</em>. Mit Press.
</div>
<div id="ref-li2024multimodal" class="csl-entry" role="listitem">
Li, C., Gan, Z., Yang, Z., Yang, J., Li, L., Wang, L., Gao, J., e.a. (2024). Multimodal foundation models: From specialists to general-purpose assistants. <em>Foundations and Trends<span></span> in Computer Graphics and Vision</em>, <em>16</em>(1-2), 1–214.
</div>
<div id="ref-liu2024sora" class="csl-entry" role="listitem">
Liu, Y., Zhang, K., Li, Y., Yan, Z., Gao, C., Chen, R., Yuan, Z., Huang, Y., Sun, H., Gao, J., e.a. (2024). Sora: A review on background, technology, limitations, and opportunities of large vision models. <em>arXiv preprint arXiv:2402.17177</em>.
</div>
<div id="ref-mara2021user" class="csl-entry" role="listitem">
Mara, M., Stein, J.-P., Latoschik, M. E., Lugrin, B., Schreiner, C., Hostettler, R., &amp; Appel, M. (2021). User responses to a humanoid robot observed in real life, virtual reality, 3D and 2D. <em>Frontiers in psychology</em>, <em>12</em>, 633178.
</div>
<div id="ref-mcdermott2007artificial" class="csl-entry" role="listitem">
McDermott, D. (2007). Artificial intelligence and consciousness. <em>The Cambridge handbook of consciousness</em>, 117–150.
</div>
<div id="ref-pan2024unifying" class="csl-entry" role="listitem">
Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., &amp; Wu, X. (2024). Unifying large language models and knowledge graphs: A roadmap. <em>IEEE Transactions on Knowledge and Data Engineering</em>.
</div>
<div id="ref-reed2016generative" class="csl-entry" role="listitem">
Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., &amp; Lee, H. (2016). Generative adversarial text to image synthesis. <em>International conference on machine learning</em>, 1060–1069.
</div>
<div id="ref-rojas1997konrad" class="csl-entry" role="listitem">
Rojas, R. (1997). Konrad Zuse’s legacy: the architecture of the Z1 and Z3. <em>IEEE Annals of the History of Computing</em>, <em>19</em>(2), 5–16.
</div>
<div id="ref-schmidhuber2007godel" class="csl-entry" role="listitem">
Schmidhuber, J. (2007). G<span>ö</span>del machines: Fully self-referential optimal universal self-improvers. In <em>Artificial general intelligence</em> (pp. 199–226). Springer.
</div>
<div id="ref-seaborn2023not" class="csl-entry" role="listitem">
Seaborn, K., Barbareschi, G., &amp; Chandra, S. (2023). Not only WEIRD but <span>‘uncanny’</span>? A systematic review of diversity in Human–Robot Interaction research. <em>International Journal of Social Robotics</em>, <em>15</em>(11), 1841–1870.
</div>
<div id="ref-sejnowski2023large" class="csl-entry" role="listitem">
Sejnowski, T. J. (2023). Large language models and the reverse turing test. <em>Neural computation</em>, <em>35</em>(3), 309–342.
</div>
<div id="ref-siemens2022human" class="csl-entry" role="listitem">
Siemens, G., Marmolejo-Ramos, F., Gabriel, F., Medeiros, K., Marrone, R., Joksimovic, S., &amp; Laat, M. de. (2022). Human and artificial cognition. <em>Computers and Education: Artificial Intelligence</em>, <em>3</em>, 100107.
</div>
<div id="ref-tan2024naturalspeech" class="csl-entry" role="listitem">
Tan, X., Chen, J., Liu, H., Cong, J., Zhang, C., Liu, Y., Wang, X., Leng, Y., Yi, Y., He, L., e.a. (2024). Naturalspeech: End-to-end text-to-speech synthesis with human-level quality. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>.
</div>
<div id="ref-Turing1950ai" class="csl-entry" role="listitem">
Turing, A. M. (1950). <span>I.—Computing Machinery and Intelligence</span>. <em>Mind</em>, <em>LIX</em>(236), 433–460. <a href="https://doi.org/10.1093/mind/LIX.236.433">https://doi.org/10.1093/mind/LIX.236.433</a>
</div>
<div id="ref-van2020survey" class="csl-entry" role="listitem">
Van Engelen, J. E., &amp; Hoos, H. H. (2020). A survey on semi-supervised learning. <em>Machine learning</em>, <em>109</em>(2), 373–440.
</div>
<div id="ref-van2021sustainable" class="csl-entry" role="listitem">
Van Wynsberghe, A. (2021). Sustainable AI: AI for sustainability and the sustainability of AI. <em>AI and Ethics</em>, <em>1</em>(3), 213–218.
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). Attention is all you need. <em>Advances in Neural Information Processing Systems</em>.
</div>
<div id="ref-vinge1993technological" class="csl-entry" role="listitem">
Vinge, V. (1993). Technological singularity. <em>VISION-21 Symposium sponsored by NASA Lewis Research Center and the Ohio Aerospace Institute</em>, 30–31.
</div>
<div id="ref-von2008recaptcha" class="csl-entry" role="listitem">
Von Ahn, L., Maurer, B., McMillen, C., Abraham, D., &amp; Blum, M. (2008). recaptcha: Human-based character recognition via web security measures. <em>Science</em>, <em>321</em>(5895), 1465–1468.
</div>
<div id="ref-enwiki:1250511271" class="csl-entry" role="listitem">
Wikipedia contributors. (2024a). <em>Moore’s law — <span>Wikipedia</span><span>,</span> The Free Encyclopedia</em>. <a href="https://en.wikipedia.org/w/index.php?title=Moore%27s_law&amp;oldid=1250511271" class="uri">https://en.wikipedia.org/w/index.php?title=Moore%27s_law&amp;oldid=1250511271</a>.
</div>
<div id="ref-enwiki:1238847142" class="csl-entry" role="listitem">
Wikipedia contributors. (2024b). <em>Wheat and chessboard problem — <span>Wikipedia</span><span>,</span> The Free Encyclopedia</em>. <a href="https://en.wikipedia.org/w/index.php?title=Wheat_and_chessboard_problem&amp;oldid=1238847142" class="uri">https://en.wikipedia.org/w/index.php?title=Wheat_and_chessboard_problem&amp;oldid=1238847142</a>.
</div>
<div id="ref-wu2022sustainable" class="csl-entry" role="listitem">
Wu, C.-J., Raghavendra, R., Gupta, U., Acun, B., Ardalani, N., Maeng, K., Chang, G., Aga, F., Huang, J., Bai, C., e.a. (2022). Sustainable ai: Environmental implications, challenges and opportunities. <em>Proceedings of Machine Learning and Systems</em>, <em>4</em>, 795–813.
</div>
<div id="ref-zha2023data" class="csl-entry" role="listitem">
Zha, D., Bhat, Z. P., Lai, K.-H., Yang, F., Jiang, Z., Zhong, S., &amp; Hu, X. (2023). Data-centric artificial intelligence: A survey. <em>arXiv preprint arXiv:2303.10158</em>.
</div>
<div id="ref-zhou2023comprehensive" class="csl-entry" role="listitem">
Zhou, C., Li, Q., Li, C., Yu, J., Liu, Y., Wang, G., Zhang, K., Ji, C., Yan, Q., He, L., e.a. (2023). A comprehensive survey on pretrained foundation models: A history from bert to chatgpt. <em>arXiv preprint arXiv:2302.09419</em>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Met een totaal van bijna 7 miljard smartphones, zie <a href="https://www.statista.com/statistics/330695/number-of-smartphone-users-worldwide/" target="_blank">Statistica</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span class="math inline">\(5*2^4 = 80\)</span> en <span class="math inline">\(5*2^{52}=22.517.998.136.852.480\)</span> cm. Een aloud verhaal over rijst op een schaakbord laat dit verband ook mooi blijken <span class="citation" data-cites="enwiki:1238847142">(<a href="referenties.html#ref-enwiki:1238847142" role="doc-biblioref">Wikipedia contributors, 2024b</a>)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><span class="math inline">\(10*2^4=160%\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Vinge benoemt ook de term <strong>Intelligence Amplification</strong> (IA) om inderdaad een soort mens/machine-symbiose te duiden die hierin zou kunnen helpen <span class="citation" data-cites="vinge1993technological">(<a href="referenties.html#ref-vinge1993technological" role="doc-biblioref">Vinge, 1993</a>)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Dit is een soort middenvorm tussen <em>supervised</em> en <em>unsupervised learning</em>, waarmee bijvoorbeeld wordt gekeken naar de verdeling van de data en wat dit kan zeggen over individuele datapunten.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Misschien is dat wel <em>wishful thinking</em>, maar de ontwikkelingen zijn er gelukkig.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Zie ook het concept van <strong>Gödel machines</strong> die hun eigen code kunnen herschrijven om zichzelf te verbeteren <span class="citation" data-cites="schmidhuber2007godel">(<a href="referenties.html#ref-schmidhuber2007godel" role="doc-biblioref">Schmidhuber, 2007</a>)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Technieken als semi-supervised learning lenen zich hier goed voor.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Een grapje dat vaker wordt gemaakt is dat wat mensen en computers onderscheidt, het beantwoorden van <strong>CAPTCHA</strong>’s is. CAPTCHA staat voor Completely Automated Public Turing test to tell Computers and Humans Apart. Bekende voorbeelden zijn de de reCAPTCHA-testen van Google die gebruikt worden op websites, bijvoorbeeld door een aantal plaatjes aan te klikken waarop auto’s staan. Dit wordt dan gebruikt om te bevestigen dat een mens probeert in te loggen in plaats van een softwareprogramma. En daarnaast wordt dit ook gebruikt om informatie in te winnen om machinelearningmodellen te trainen: zo goed als gratis annotatie van data door honderden miljoenen mensen op het internet <span class="citation" data-cites="von2008recaptcha">(<a href="referenties.html#ref-von2008recaptcha" role="doc-biblioref">Von Ahn e.a., 2008</a>)</span>.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Zoals met <a href="https://openai.com/index/sora/" target="_blank">Sora van OpenAI</a> <span class="citation" data-cites="liu2024sora">(<a href="referenties.html#ref-liu2024sora" role="doc-biblioref">Liu e.a., 2024</a>)</span>. Tastbare, fysieke AI in een realistische, menselijke vorm (humanoïde robots) lijkt echter nog ver weg <span class="citation" data-cites="mara2021user seaborn2023not">(<a href="referenties.html#ref-mara2021user" role="doc-biblioref">Mara e.a., 2021</a>; <a href="referenties.html#ref-seaborn2023not" role="doc-biblioref">Seaborn e.a., 2023</a>)</span>.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Affectieve Intelligentie? Met huidige chatbots op basis van LLM’s kunnen dialogen gevoerd worden die lijken op interpersoonlijke relaties en als zodanig gezien worden door mensen. Dit kan zover gaan als een liefdesverhouding met zulke chatbots <span class="citation" data-cites="brandtzaeg2022my">(<a href="referenties.html#ref-brandtzaeg2022my" role="doc-biblioref">Brandtzaeg e.a., 2022</a>.)</span><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Gekopieerd!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Gekopieerd!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./20_uitdagingen.html" class="pagination-link" aria-label="Uitdagingen: Het belang van wederzijds begrip">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Uitdagingen: Het belang van wederzijds begrip</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./40_actie.html" class="pagination-link" aria-label="Actie: Samen verantwoordelijk">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Actie: Samen verantwoordelijk</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>